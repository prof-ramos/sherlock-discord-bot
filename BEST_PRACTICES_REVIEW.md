# Revis√£o de Boas Pr√°ticas de C√≥digo: SherlockRamosBot

### Sum√°rio Executivo

A an√°lise da codebase do SherlockRamosBot revela uma base s√≥lida com uso de ferramentas modernas e
uma arquitetura de banco de dados bem pensada. No entanto, o projeto sofre de um problema
arquitet√¥nico significativo centrado no arquivo `src/main.py`, que atua como um "objeto deus",
concentrando excessiva responsabilidade. Este padr√£o anti-arquitetural compromete a
manutenibilidade, testabilidade e escalabilidade do projeto.

As recomenda√ß√µes focam na modulariza√ß√£o de `src/main.py`, na ado√ß√£o de inje√ß√£o de depend√™ncia e na
automa√ß√£o da garantia de qualidade de c√≥digo via CI/CD.

---

### 1. Problemas Cr√≠ticos (Must-fix)

#### 1.1. `src/main.py`: O "Objeto Deus"

- **Problema**: O arquivo `src/main.py` acumula responsabilidades demais. Ele gerencia a
  inicializa√ß√£o do cliente Discord, o registro de comandos (slash commands), o tratamento de eventos
  (`on_message`), a l√≥gica de modera√ß√£o, a intera√ß√£o com o servi√ßo de banco de dados e as chamadas
  para o servi√ßo de completude da IA. Isso o torna um "objeto deus" (god object).
- **Por que √© Ineficiente**:
  - **Viola√ß√£o do SRP (Princ√≠pio da Responsabilidade √önica)**: Uma √∫nica classe/m√≥dulo tem m√∫ltiplas
    raz√µes para mudar. Qualquer altera√ß√£o em comandos, eventos ou l√≥gica de neg√≥cios afeta
    `main.py`.
  - **Baixa Testabilidade**: √â extremamente dif√≠cil escrever testes unit√°rios para as fun√ß√µes em
    `main.py` sem mockar uma vasta quantidade de depend√™ncias do Discord e de servi√ßos internos.
  - **Baixa Manutenibilidade**: O arquivo √© extenso e complexo, dificultando a compreens√£o,
    depura√ß√£o e modifica√ß√£o.
  - **Escalabilidade Limitada**: Adicionar novos comandos ou funcionalidades de eventos torna
    `main.py` ainda maior e mais intrat√°vel.
- **Impacto no Desempenho (Indireto)**: Embora n√£o seja uma quest√£o de desempenho direto de
  CPU/mem√≥ria, a complexidade introduzida pode levar a bugs e dificultar otimiza√ß√µes futuras.
- **Como Otimizar**: Refatorar `src/main.py` utilizando o conceito de "Cogs" (ou Extensions) do
  `discord.py`. Cada Cog seria respons√°vel por um conjunto espec√≠fico de comandos ou eventos,
  aderindo ao SRP.
- **Nota de `discord.py` (Context7)**: Cogs herdam de `commands.Cog` e s√£o adicionados de forma
  ass√≠ncrona com `await bot.add_cog(...)`. Para listeners de eventos, use
  `@commands.Cog.listener()`. Se quiser agrupar app commands, considere `commands.GroupCog`, que
  exp√µe `cog.app_command` como grupo.

- **Exemplo de C√≥digo (Alternativa Otimizada)**:

  **Antes (simplificado de `main.py`)**:

  ```python
  # src/main.py (antes)
  import discord
  from discord.ext import commands # Nova importa√ß√£o
  # ... outras importa√ß√µes ...

  class MyBot(commands.Bot):
      def __init__(self):
          super().__init__(command_prefix='!', intents=discord.Intents.default())
          # ... setup de intents ...

      async def on_ready(self):
          print(f'{self.user} has connected to Discord!')
          # ... l√≥gica on_ready ...

      async def on_message(self, message):
          # ... l√≥gica on_message ...
          pass # Chamar processamento em Cog

  # ... slash commands como @tree.command ...
  ```

  **Depois (estrutura proposta com Cogs)**:

  Crie um novo diret√≥rio `src/cogs`.

  **`src/cogs/chat.py`**:

  ```python
  # src/cogs/chat.py
  from typing import Optional

  import discord
  from discord import app_commands
  from discord.ext import commands

  from src.completion import generate_completion_response, process_response
  from src.database import DatabaseService, db_service
  from src.moderation import moderate_message, send_moderation_blocked_message, send_moderation_flagged_message
  from src.constants import ACTIVATE_THREAD_PREFIX, AVAILABLE_MODELS, DEFAULT_MODEL
  from src.base import ThreadConfig
  from src.utils import logger, should_block

  class ChatCog(commands.Cog):
      def __init__(self, bot: commands.Bot, db_service_instance: DatabaseService) -> None:
          self.bot = bot
          self.db_service = db_service_instance # Inje√ß√£o de depend√™ncia

      @app_commands.command(name="chat", description="Create a new thread for conversation")
      @app_commands.checks.has_permissions(send_messages=True)
      # ... outras permiss√µes ...
      @app_commands.describe(message="The first prompt to start the chat with")
      # ... outros argumentos ...
      async def chat_command(
          self,
          interaction: discord.Interaction,
          message: str,
          model: AVAILABLE_MODELS = DEFAULT_MODEL,
          temperature: Optional[float] = 1.0,
          max_tokens: Optional[int] = 512,
      ) -> None:
          # L√≥gica do comando /chat move-se para c√°
          # Utiliza self.db_service para interagir com o DB
          logger.info("Chat command invoked by %s", interaction.user)
          # ... valida√ß√µes, modera√ß√£o, cria√ß√£o de thread, etc. ...

          thread_config = ThreadConfig(model=model, max_tokens=max_tokens, temperature=temperature)
          await self.db_service.save_thread( # Acessa db_service injetado
              thread_id=thread.id,
              guild_id=interaction.guild_id,
              user_id=interaction.user.id,
              config=thread_config
          )
          # ... restante da l√≥gica do comando ...

      @commands.Cog.listener()
      async def on_message(self, message: discord.Message) -> None:
          # Use listeners para eventos espec√≠ficos antes espalhados em main.py
          pass

  async def setup(bot: commands.Bot) -> None:
      # db_service global ainda precisaria ser passado, ou usar uma abordagem de DI mais robusta
      await bot.add_cog(ChatCog(bot, db_service))
  ```

  **`src/main.py` (depois)**:

  ```python
  # src/main.py (depois)
  import asyncio
  import logging
  import discord
  from discord.ext import commands # Nova importa√ß√£o

  from src.constants import DISCORD_BOT_TOKEN, BOT_INVITE_URL, ALLOWED_SERVER_IDS
  from src.database import db_service # Ainda como global, ser√° abordado na pr√≥xima se√ß√£o
  from src.cogs.chat import ChatCog # Importa o novo Cog
  from src.profiling import log_metrics_summary_sync # Importa a fun√ß√£o sync para atexit
  import atexit # Importa atexit

  logger = logging.getLogger(__name__)
  logging.basicConfig(...) # ... configura√ß√£o de logging ...

  class SherlockRamosBot(commands.Bot):
      def __init__(self):
          intents = discord.Intents.default()
          intents.message_content = True # Certifique-se de que isso est√° habilitado no portal do desenvolvedor
          super().__init__(command_prefix='!', intents=intents) # Prefixo de comando pode ser in√∫til se usar apenas slash commands
          self.db_service = db_service # Passa o servi√ßo de DB para o bot, para que os Cogs possam acess√°-lo

      async def setup_hook(self):
          # Carrega Cogs aqui
          await self.add_cog(ChatCog(self, self.db_service)) # Instancia e adiciona o Cog
          # ... outros Cogs ...

          # Sincroniza comandos globais e por guild
          for guild_id in ALLOWED_SERVER_IDS:
              guild = discord.Object(id=guild_id)
              self.tree.copy_global_to(guild=guild)
              await self.tree.sync(guild=guild)
              logger.info(f"Synced commands to guild {guild_id}")
          await self.tree.sync()
          logger.info("Global command sync complete")


      async def on_ready(self):
          logger.info(f"We have logged in as {self.user}. Invite URL: {BOT_INVITE_URL}")
          # ... l√≥gica de on_ready restante ...

      async def on_message(self, message: discord.Message):
          if message.author == self.user:
              return
          # Se for uma thread de conversa do bot ou men√ß√£o, encaminha
          # A l√≥gica de on_message se torna um 'dispatcher'
          # Cogs podem ter listeners para eventos espec√≠ficos

          # Exemplo simplificado:
          if self.user in message.mentions:
              # Chame uma fun√ß√£o no Cog que lida com men√ß√µes
              pass
          elif isinstance(message.channel, discord.Thread) and message.channel.owner_id == self.user.id:
              # Chame uma fun√ß√£o no Cog que lida com mensagens em threads do bot
              pass

          # Permite que os comandos base do bot (se houver) ainda funcionem
          await self.process_commands(message)

  def run_bot() -> None:
      bot = SherlockRamosBot()
      bot.run(DISCORD_BOT_TOKEN)

  if __name__ == "__main__":
      atexit.register(log_metrics_summary_sync)
      run_bot()
  ```

- **Benef√≠cios**: Aumenta drasticamente a manutenibilidade e testabilidade. Permite que
  desenvolvedores trabalhem em funcionalidades isoladas sem afetar outras partes do bot.

---

### 2. Prioridade Alta (Important improvements)

#### 2.1. Inje√ß√£o de Depend√™ncia para Servi√ßos

- **Problema**: Servi√ßos como `db_service` e `rag_service` s√£o importados e usados diretamente como
  singletons globais em v√°rios m√≥dulos (ex: `main.py`, `completion.py`).
- **Por que Viola Boas Pr√°ticas**:
  - **Viola√ß√£o do DIP (Princ√≠pio da Invers√£o de Depend√™ncia)**: M√≥dulos de alto n√≠vel (como
    `main.py`) dependem diretamente de implementa√ß√µes de baixo n√≠vel (singletons globais).
  - **Dificulta a Testabilidade**: Para testar um m√≥dulo que usa um singleton global, √© necess√°rio
    mockar o singleton, o que pode ser complicado e propenso a erros.
  - **Flexibilidade Reduzida**: Trocar a implementa√ß√£o de um servi√ßo (ex: mudar de `chromadb` para
    outro DB vetorial) exigiria modificar m√∫ltiplos arquivos.
- **Como Otimizar**: Utilizar Inje√ß√£o de Depend√™ncia (DI). Em vez de importar o singleton global, os
  servi√ßos s√£o "injetados" (passados como argumentos) para as classes ou fun√ß√µes que precisam deles.

- **Exemplo de C√≥digo (Alternativa Otimizada)**:

  **Antes (em `completion.py`)**:

  ```python
  # src/completion.py (antes, simplificado)
  from src.database import db_service # Importa√ß√£o direta
  from src.rag_service import rag_service # Importa√ß√£o direta
  # ...

  async def generate_completion_response(...):
      # ...
      await db_service.log_message(...) # Uso direto
      relevant_docs = rag_service.query(...) # Uso direto
      # ...
  ```

  **Depois (estrutura proposta)**:

  ```python
  # src/completion.py (depois, simplificado)
  # Remove importa√ß√µes diretas de singletons de servi√ßo
  # from src.database import db_service # REMOVER
  # from src.rag_service import rag_service # REMOVER

  from src.base import DatabaseService, RAGService # Importar interfaces/classes dos servi√ßos

  class CompletionService:
      def __init__(self, db_service: DatabaseService, rag_service: RAGService):
          self.db_service = db_service
          self.rag_service = rag_service

      async def generate_completion_response(
          self, messages: List[Message], user: discord.Member, thread_config: ThreadConfig
      ) -> CompletionResponse:
          # ...
          await self.db_service.log_message(...) # Usa o servi√ßo injetado
          relevant_docs = self.rag_service.query(...) # Usa o servi√ßo injetado
          # ...

  # Onde este servi√ßo for instanciado (ex: no setup_hook do bot ou no Cog):
  # completion_service = CompletionService(db_service_instance, rag_service_instance)
  ```

- **Benef√≠cios**: Melhora a testabilidade (pode-se injetar mocks), aumenta a flexibilidade para
  trocar implementa√ß√µes e reduz o acoplamento entre m√≥dulos.

#### 2.2. Automa√ß√£o da Garantia de Qualidade de C√≥digo via CI/CD

- **Problema**: O projeto tem `ruff` (linting/formata√ß√£o) e `mypy` (verifica√ß√£o de tipos)
  configurados em `pyproject.toml`, o que √© excelente. No entanto, n√£o h√° um processo automatizado
  para garantir que essas ferramentas sejam executadas em cada Pull Request ou commit. Isso permite
  que c√≥digo que n√£o segue as melhores pr√°ticas ou tem erros de tipo seja mesclado.
- **Por que Viola Boas Pr√°ticas**: Introduz technical debt, reduz a consist√™ncia do c√≥digo, pode
  introduzir bugs e dificulta a revis√£o de c√≥digo manual.
- **Como Otimizar**: Implementar um pipeline de CI/CD (Integra√ß√£o Cont√≠nua/Entrega Cont√≠nua) usando
  GitHub Actions (dado que o reposit√≥rio est√° no GitHub).

- **Exemplo de C√≥digo (GitHub Actions Workflow - `.github/workflows/ci.yml`)**:

  ```yaml
  # .github/workflows/ci.yml
  name: CI/CD SherlockRamosBot

  on:
    push:
      branches:
        - main
    pull_request:
      branches:
        - main

  jobs:
    build:
      runs-on: ubuntu-latest

      steps:
        - name: Checkout code
          uses: actions/checkout@v4

        - name: Set up Python
          uses: actions/setup-python@v5
          with:
            python-version: '3.13' # Alinhar com a vers√£o do projeto

        - name: Install uv
          run: |
            pip install uv

        - name: Install dependencies
          run: uv sync --dev

        - name: Run Ruff (Linting and Formatting)
          run: uv run ruff check .
          # Opcional: uv run ruff format . --check para verificar formata√ß√£o

        - name: Run Mypy (Type Checking)
          run: uv run mypy src

        - name: Run Pytest (Unit Tests)
          run: uv run pytest
  ```

- **Benef√≠cios**: Garante a consist√™ncia do c√≥digo, captura erros precocemente, melhora a qualidade
  geral do software e acelera o processo de revis√£o de c√≥digo.

---

### 3. Prioridade M√©dia (Recommended changes)

#### 3.1. Modulariza√ß√£o do `CompletionService`

- **Problema**: A fun√ß√£o `generate_completion_response` em `src/completion.py` ainda concentra
  v√°rias responsabilidades: verifica√ß√£o de cache, consulta ao servi√ßo RAG e chamada √† API da LLM.
- **Por que Viola Boas Pr√°ticas**: Viola o SRP, tornando a fun√ß√£o mais complexa do que o necess√°rio
  e dificultando a altera√ß√£o de uma parte da l√≥gica sem impactar as outras.
- **Como Otimizar**: Decompor `generate_completion_response` em fun√ß√µes ou m√©todos menores e mais
  focados.

- **Exemplo de C√≥digo (Alternativa Otimizada)**:

  **Antes (simplificado de `completion.py`)**:

  ```python
  # src/completion.py (antes, simplificado)
  async def generate_completion_response(...):
      cached_response = response_cache.get(...)
      if cached_response:
          return cached_response

      relevant_docs = rag_service.query(...)
      # ... construir prompt ...
      llm_response = await client.chat.completions.create(...)

      response_cache.set(...)
      return CompletionResponse(...)
  ```

  **Depois (estrutura proposta)**:

  ```python
  # src/completion.py (depois, simplificado)
  class CompletionService:
      def __init__(self, cache_service, rag_service, llm_client):
          self.cache = cache_service
          self.rag = rag_service
          self.llm_client = llm_client

      async def _get_cached_response(self, messages, model, temperature, max_tokens):
          return self.cache.get(messages, model, temperature, max_tokens)

      async def _get_rag_context(self, query_text):
          return self.rag.query(query_text)

      async def _call_llm_api(self, messages_with_context, model, temperature, max_tokens):
          # ... l√≥gica de chamada da API LLM ...
          pass

      async def generate_completion_response(
          self, messages: List[Message], user: discord.Member, thread_config: ThreadConfig
      ) -> CompletionResponse:
          cached_response = await self._get_cached_response(
              messages, thread_config.model, thread_config.temperature, thread_config.max_tokens
          )
          if cached_response:
              return cached_response

          query_text = messages[-1].text # Exemplo: √∫ltima mensagem para consulta RAG
          relevant_docs = await self._get_rag_context(query_text)

          # ... construir prompt com contexto RAG ...
          llm_response = await self._call_llm_api(
              messages_with_context, thread_config.model, thread_config.temperature, thread_config.max_tokens
          )

          self.cache.set(
              messages, thread_config.model, llm_response,
              thread_config.temperature, thread_config.max_tokens
          )
          return CompletionResponse(...)
  ```

- **Benef√≠cios**: Aumenta a clareza do c√≥digo, facilita a manuten√ß√£o, permite testar cada etapa
  (cache, RAG, LLM) isoladamente e torna a fun√ß√£o `generate_completion_response` mais enxuta e
  leg√≠vel.

#### 3.2. Logging das Estat√≠sticas do Cache

- **Problema**: O m√≥dulo `src/cache.py` inclui um m√©todo `log_stats()` que fornece m√©tricas valiosas
  sobre a efic√°cia do cache (hits, misses, taxa de acertos). No entanto, este m√©todo n√£o √© chamado
  em nenhum lugar do c√≥digo.
- **Por que Viola Boas Pr√°ticas**: Ignora uma ferramenta de observabilidade j√° implementada, o que
  dificulta o monitoramento do desempenho do cache e a identifica√ß√£o de problemas (ex: baixa taxa de
  acertos, cache expirando rapidamente).
- **Como Otimizar**: Registrar as estat√≠sticas do cache periodicamente (se poss√≠vel) ou, no m√≠nimo,
  no encerramento da aplica√ß√£o.

- **Exemplo de C√≥digo (Alternativa Otimizada)**:

  Dado que j√° implementamos o `atexit.register(log_metrics_summary_sync)` em `src/main.py`, podemos
  estender isso para incluir as estat√≠sticas do cache.

  **Em `src/profiling.py` (adicionar `cache_stats` ao summary)**:

  ```python
  # src/profiling.py
  # ...
  from src.cache import response_cache # Importar o cache global

  # ... na fun√ß√£o log_metrics_summary_sync() ...
  def log_metrics_summary_sync() -> None:
      # ... (c√≥digo existente para m√©tricas de performance) ...

      # Adicionar estat√≠sticas do cache
      cache_s = response_cache.stats
      print(
          f"üì¶ Cache Stats: size={cache_s['size']}/{cache_s['max_size']}, "
          f"hits={cache_s['hits']}, misses={cache_s['misses']}, "
          f"hit_rate={cache_s['hit_rate']}"
      )
  ```

- **Benef√≠cios**: Fornece insights sobre a efic√°cia do cache, permitindo ajustes nos par√¢metros
  (`max_size`, `ttl_seconds`) para otimizar o uso e reduzir chamadas desnecess√°rias √† LLM e ao
  servi√ßo RAG.

---

### 4. Prioridade Baixa (Nice-to-have enhancements)

#### 4.1. Hash Mais R√°pido para Chaves de Cache

- **Problema**: A fun√ß√£o `_hash_key` em `src/cache.py` utiliza `hashlib.sha256` para gerar chaves de
  cache. Embora seguro, SHA-256 √© um algoritmo criptogr√°fico projetado para seguran√ßa, n√£o para
  velocidade.
- **Por que Viola Boas Pr√°ticas**: Uso de um algoritmo mais pesado do que o necess√°rio para uma
  tarefa n√£o-criptogr√°fica, podendo introduzir uma pequena lat√™ncia.
- **Como Otimizar**: Para hashing de chaves de cache onde a seguran√ßa criptogr√°fica n√£o √©
  primordial, um algoritmo de hashing n√£o-criptogr√°fico mais r√°pido (como `xxhash` ou o `hash()`
  embutido do Python, embora com ressalvas sobre consist√™ncia entre execu√ß√µes) seria mais eficiente.

- **Exemplo de C√≥digo (Alternativa Otimizada)**:

  ```python
  # src/cache.py (simplificado)
  import hashlib
  # import xxhash # Se for instalar uma biblioteca externa

  class LRUCache:
      # ...
      def _hash_key(...):
          # ...
          content = f"{model}:{temperature}:{max_tokens}:{convo_str}"
          content = f"{model}:{temperature}:{max_tokens}:{convo_str}"
          # return xxhash.xxh64(content.encode()).hexdigest() # Exemplo com xxhash (r√°pido, n√£o criptogr√°fico)
          return hashlib.sha256(content.encode()).hexdigest() # SHA-256 (seguro, padr√£o)
          # Nota: Evite MD5/SHA1 a menos que compatibilidade legada seja estritamente necess√°ria.

  ```

- **Benef√≠cios**: Ganhos marginais de desempenho na gera√ß√£o de chaves de cache, especialmente para
  sistemas com alt√≠ssima taxa de requisi√ß√µes.

---

Esta revis√£o visa guiar o desenvolvimento futuro do SherlockRamosBot, priorizando a estabilidade,
manutenibilidade e escalabilidade do projeto.
